Automatically generated by Mendeley Desktop 1.19.8
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@misc{Moodle,
author = {Moodle},
title = {{About Moodle - MoodleDocs}},
url = {https://docs.moodle.org/38/en/About{\_}Moodle},
urldate = {2020-04-07},
year = {2018}
}
@book{Sommerville2011,
annote = {Accession Number: uow.b1705092; Other Notes: Includes index.; Includes bibliographical references and indexes.; Publication Type: Book; Physical Description: xv, 773 p. : ill. ; 24 cm.; Language: English; LCCN: 2009053058},
author = {Sommerville, Ian},
edition = {9th ed.},
isbn = {9780137035151},
keywords = {Software engineering},
publisher = {Pearson},
title = {{Software engineering / Ian Sommerville.}},
year = {2011}
}
@techreport{ConsumersInternational2018,
author = {{Consumers International}},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Consumers International - 2018 - The state of data protection rules around the world A briefing FOR CONSUMER ORGANISATIONS.pdf:pdf},
title = {{The state of data protection rules around the world: A briefing FOR CONSUMER ORGANISATIONS}},
year = {2018}
}
@article{Cavoukian2009,
abstract = {Implementation and Mapping of Fair Information Practices},
author = {Cavoukian, Ann},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Cavoukian - 2009 - Privacy by Design - The 7 foundational principles - Implementation and mapping of fair information practices.pdf:pdf},
isbn = {0969-4765},
issn = {1876-0678},
journal = {Information and Privacy Commissioner of Ontario, Canada},
pages = {10},
title = {{Privacy by Design - The 7 foundational principles - Implementation and mapping of fair information practices}},
year = {2009}
}
@article{Duncan2007a,
abstract = {New technologies are being developed to protect the privacy of individuals in today's information society.},
author = {Duncan, George},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Duncan - 2007 - Engineering Privacy by design.pdf:pdf},
issn = {00368075},
journal = {Science},
number = {5842},
pages = {1178--1179},
pmid = {17761870},
title = {{Engineering: Privacy by design}},
volume = {317},
year = {2007}
}
@misc{McGraw1992,
abstract = {Some of the shortcomings in interpretability and generalizability of the effect size statistics currently available to researchers can be overcome by a statistic that expresses how often a score sampled from one distribution will be greater than a score sampled from another distribution. The statistic, the common language effect size indicator, is easily calculated from sample means and variances (or from proportions in the case of nominal-level data). It can be used for expressing the effect observed in both independent and related sample designs and in both 2-group and n-group designs. Empirical tests show it to be robust to violations of the normality assumption, particularly when the variances in the 2 parent distributions are equal. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
address = {US},
author = {McGraw, Kenneth O and Wong, S P},
booktitle = {Psychological Bulletin},
keywords = {Effect Size (Statistical)},
number = {2},
pages = {361--365},
publisher = {American Psychological Association},
title = {{A common language effect size statistic}},
volume = {111},
year = {1992}
}
@article{Antn2004,
abstract = {The increasing use of personal information on web-based applications can result in unexpected disclosures. Consumers often have only the stated website policies as a guide to how their information is used, and thus on which to base their browsing transaction decisions. However, each policy is different, and it is difficult -- if not impossible -- for the average user to compare and comprehend these policies. This paper presents a taxonomy of privacy requirements for websites. Using goal-mining, the extraction of pre-requirements goals from post-requirements text artefacts, we analysed an initial set of Internet privacy policies to develop the taxonomy. This taxonomy was then validated during a second goal extraction exercise, involving privacy policies from a range of health care related websites. This validation effort enabled further refinement to the taxonomy, culminating in two classes of privacy requirements: protection goals and vulnerablities. Protection goals express the desired protection of consumer privacy rights, whereas vulnerabilities describe requirements that potentially threaten consumer privacy. The identified taxonomy categories are useful for analysing implicit internal conflicts within privacy policies, the corresponding websites, and their manner of operation. These categories can be used by website designers to reduce website privacy vulnerabilities and ensure that their stated and actual policies are consistent with each other. The same categories can be used by customers to evaluate and understand policies and their limitations. Additionally, the policies have potential use by third-party evaluators of site policies and conflicts.},
author = {Ant{\'{o}}n, Annie I. and Earp, Julia B.},
file = {:C$\backslash$:/Users/ps642/Downloads/6-A requirements taxonomy for reducing Web site privacy vulnerabilities (1).pdf:pdf},
journal = {Requirements Engineering},
keywords = {privacy requirements {\ae} security,requirements},
number = {3},
pages = {169--185},
title = {{A requirements taxonomy for reducing Web site privacy vulnerabilities}},
volume = {9},
year = {2004}
}
@inproceedings{Anton1996,
abstract = {Goals are a logical mechanism for identifying, organizing and justifying software requirements. Strategies are needed for the initial identification and construction of goals. In this paper we discuss goals from the perspective of two themes: goal analysis and goal evolution. We begin with an overview of the goal-based method we have developed and summarize our experiences in applying our method to a relatively large example. We illustrate some of the issues that practitioners face when using a goal-based approach to specify the requirements for a system and close the paper with a discussion of needed future research on goal-based requirements analysis and evolution.},
author = {Ant{\'{o}}n, Annie I.},
booktitle = {Proceedings of the IEEE International Conference on Requirements Engineering},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Anton - 1996 - Goal-based requirements analysis.pdf:pdf},
pages = {136--144},
publisher = {IEEE},
title = {{Goal-based requirements analysis}},
year = {1996}
}
@book{Glaser2017,
annote = {Accession Number: uow.b3095337; Other Notes: Includes index.; Description based on online resource; title from PDF title page (ebrary, viewed October 9, 2017); Publication Type: Book, eBook; Physical Description: 1 online resource (282 pages); Language: English; OCLC: 1004614945},
author = {Glaser, Barney and Strauss, Anselm L},
isbn = {9781351522168},
keywords = {Electronic books,Grounded theory,Qualitative research},
publisher = {Routledge},
title = {{The discovery of grounded theory : strategies for qualitative research}},
year = {2017}
}
@techreport{Wild1997,
author = {Wild, Chris},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Wild - 1997 - The Wilcoxon Rank-Sum Test.pdf:pdf},
institution = {Department of Statistics, University of Auckland},
issn = {0102-311X},
pages = {1--10},
title = {{The Wilcoxon Rank-Sum Test}},
year = {1997}
}
@misc{Artstein2008,
abstract = {This article is a survey of methods for measuring agreement among corpus annotators. It exposes the mathematics and underlying assumptions of agreement coefficients, covering Krippendorff's alpha as well as Scott's pi and Cohen's kappa; discusses the use of coefficients in several annotation tasks; and argues that weighted, alpha-like coefficients, traditionally less used than kappa-like measures in computational linguistics, may be more appropriate for many corpus annotation tasks-but that their use makes the interpretation of the value of the coefficient even harder. {\textcopyright} 2008 Association for Computational Linguistics.},
author = {Artstein, Ron and Poesio, Massimo},
booktitle = {Computational Linguistics},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Artstein, Poesio - 2008 - Inter-coder agreement for computational linguistics.pdf:pdf},
issn = {15309312},
number = {4},
pages = {555--596},
title = {{Inter-coder agreement for computational linguistics}},
volume = {34},
year = {2008}
}
@inproceedings{Rest2014,
abstract = {The proposal for a new privacy regulation d.d. January 25th 2012 introduces sanctions of up to 2{\%} of the annual turnover of enterprises. This elevates the importance of mitigation of privacy risks. This paper makes Privacy by Design more concrete, and positions it as the mechanism to mitigate these privacy risks. In this vision paper, we describe how design patterns may be used to make the principle of Privacy by Design specific for relevant application domains. We identify a number of privacy design patterns as examples and we argue that the art is in finding the right level of abstraction to describe a privacy design pattern: the level where the data holder, data subject and privacy risks are described. We give an extended definition of Privacy by Design and, taking Solove's model for privacy invasions as structuring principle, we describe a tool and method to use that tool to generate trust in systems by citizens.},
author = {van Rest, Jeroen and Boonstra, Daniel and Everts, Maarten and van Rijn, Martin and van Paassen, Ron},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Rest et al. - 2014 - Designing privacy-by-design.pdf:pdf},
isbn = {9783642540684},
issn = {16113349},
keywords = {Privacy,Privacy design pattern,Privacy-by-design,System engineering,Tooling,Trust},
month = {oct},
pages = {55--72},
publisher = {Springer Verlag},
title = {{Designing privacy-by-design}},
volume = {8319},
year = {2014}
}
@misc{CNET,
author = {CNET},
title = {{British Airways faces {\$}230M GDPR fine for 2018 data breach}},
url = {https://cnet.co/2EHboiu},
year = {2019}
}
@inproceedings{Gurses2011,
abstract = {The design and implementation of privacy requirements in systems is a difficult problem and requires the translation of complex social, legal and ethical concerns into systems requirements. The concept of "privacy by design" has been proposed to serve as a guideline on how to address these concerns. "Privacy by design" consists of a number of principles that can be applied from the onset of systems development to mitigate privacy concerns and achieve data protection compliance. However, these principles remain vague and leave many open questions about their application when engineering systems. In this paper we show how departing from data minimization is a necessary and foundational first step to engineer systems in line with the principles of privacy by design. We first discuss what data minimization can mean from a security engineering perspective. We then present a summary of two case studies in which privacy is achieved by minimizing different types of data, according to the purpose of each application. First, we present a privacy-preserving ePetition system, in which user's privacy is guaranteed by hiding their identity from the provider while revealing their votes. Secondly , we study a road tolling system, in which users have to be identified for billing reasons and data minimization is applied to protect further sensitive information (in this case location information). The case studies make evident that the application of data minimization does not necessarily imply anonymity, but may also be achieved by means of concealing information related to identifiable individuals. In fact, different kinds of data minimization are possible, and each system requires careful crafting of data minimization best suited for its purpose. Most importantly, the two case studies underline that the interpretation of privacy by design principles requires specific engineering expertise, contextual analysis, and a balancing of multilateral security and privacy interests. They show that privacy by design is a productive space in which there is no one way of solving the problems. Based on our analysis of the two case studies, we argue that engineering systems according to the privacy by design principles requires the development of generalizable methodologies that build upon the principle of data minimization. However , the complexity of this engineering task demands caution against reducing such methodologies to "privacy by design check lists" that can easily be ticked away for compliance reasons while not mitigating some of the risks that privacy by design is meant to address.},
author = {G{\"{u}}rses, Seda and Troncoso, Carmela and Diaz, Claudia},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/G{\"{u}}rses, Troncoso, Diaz - 2011 - Engineering Privacy by Design.pdf:pdf},
title = {{Engineering Privacy by Design}},
year = {2011}
}
@article{Maalej2013,
abstract = {Reading reference documentation is an important part of programming with application programming interfaces (APIs). Reference documentation complements the API by providing information not obvious from the API syntax. To improve the quality of reference documentation and the efficiency with which the relevant information it contains can be accessed, we must first understand its content. We report on a study of the nature and organization of knowledge contained in the reference documentation of the hundreds of APIs provided as a part of two major technology platforms: Java SDK 6 and.NET 4.0. Our study involved the development of a taxonomy of knowledge types based on grounded methods and independent empirical validation. Seventeen trained coders used the taxonomy to rate a total of 5,574 randomly sampled documentation units to assess the knowledge they contain. Our results provide a comprehensive perspective on the patterns of knowledge in API documentation: observations about the types of knowledge it contains and how this knowledge is distributed throughout the documentation. The taxonomy and patterns of knowledge we present in this paper can be used to help practitioners evaluate the content of their API documentation, better organize their documentation, and limit the amount of low-value content. They also provide a vocabulary that can help structure and facilitate discussions about the content of APIs. {\textcopyright} 1976-2012 IEEE.},
author = {Maalej, Walid and Robillard, Martin P.},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Maalej, Robillard - 2013 - Patterns of knowledge in API reference documentation(5).pdf:pdf},
issn = {00985589},
journal = {IEEE Transactions on Software Engineering},
keywords = {.NET,API documentation,Java,content analysis,data mining,empirical study,grounded method,pattern mining,software documentation},
number = {9},
pages = {1264--1282},
title = {{Patterns of knowledge in API reference documentation}},
volume = {39},
year = {2013}
}
@misc{Data,
author = {{Data Privacy Manager}},
title = {{5 biggest GDPR fines so far [2020] – Data Privacy Manager}},
url = {https://dataprivacymanager.net/5-biggest-gdpr-fines-so-far-2020/},
urldate = {2020-03-24},
year = {2020}
}
@techreport{ISO/IEC2011,
author = {ISO/IEC},
institution = {ISO/IEC},
title = {{International Standard ISO/IEC 29100}},
year = {2011}
}
@article{Gurses2016,
abstract = {Addressing privacy and data protection systematically throughout the process of engineering information systems is a daunting task. Although the research community has made significant progress in theory and in labs, meltdowns in recent years suggest that we're still struggling to address systemic privacy issues. Privacy engineering, an emerging field, responds to this gap between research and practice. It's concerned with systematizing and evaluating approaches to capture and address privacy issues with engineering information systems. This article serves to illuminate this nascent field. The authors provide a definition of privacy engineering and describe encompassing activities. They expand on these with findings from the First International Workshop on Privacy Engineering (IWPE), and conclude with future challenges.},
author = {G{\"{u}}rses, Seda and {Del {\'{A}}lamo}, Jos{\'{e}} M.},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/G{\"{u}}rses, Del {\'{A}}lamo - 2016 - Privacy Engineering Shaping an Emerging Field of Research and Practice.pdf:pdf},
journal = {IEEE Security and Privacy},
keywords = {Computer security,Data privacy,Law,Positron emission tomography,Privacy},
number = {2},
pages = {40--46},
title = {{Privacy Engineering: Shaping an Emerging Field of Research and Practice}},
volume = {14},
year = {2016}
}
@article{Spiekermann2009,
abstract = {In this paper we integrate insights from diverse islands of research on electronic privacy to offer a holistic view of privacy engineering and a systematic structure for the discipline's topics. First we discuss privacy requirements grounded in both historic and contemporary perspectives on privacy. We use a three-layer model of user privacy concerns to relate them to system operations (data transfer, storage and processing) and examine their effects on user behavior. In the second part of the paper we develop guidelines for building privacy-friendly systems. We distinguish two approaches: "privacy-by-policy" and "privacy-by-architecture." The privacy-by-policy approach focuses on the implementation of the notice and choice principles of fair information practices (FIPs), while the privacy-by-architecture approach minimizes the collection of identifiable personal data and emphasizes anonymization and client-side data storage and processing. We discuss both approaches with a view to their technical overlaps and boundaries as well as to economic feasibility. The paper aims to introduce engineers and computer scientists to the privacy research domain and provide concrete guidance on how to design privacy-friendly systems. {\textcopyright} 2009 IEEE.},
author = {Spiekermann, Sarah and Cranor, Lorrie Faith},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Spiekermann, Cranor - 2009 - Engineering privacy.pdf:pdf},
issn = {00985589},
journal = {IEEE Transactions on Software Engineering},
keywords = {Anonymity,Identification,Privacy,Privacy-enhancing technologies,Security},
number = {1},
pages = {67--82},
title = {{Engineering privacy}},
volume = {35},
year = {2009}
}
@article{Li1,
author = {Li, He and Yu, Lu and He, Wu},
issn = {1097-198X},
journal = {Journal of global information technology management : JGITM},
number = {1},
pages = {1--6},
publisher = {Ivy League Pub},
title = {{The Impact of GDPR on Global Technology Development}},
volume = {22},
year = {2019}
}
@book{Young2004,
annote = {Accession Number: uow.b1851370; Corporate Authors: ebrary, Inc., ProQuest Ebooks.; Other Notes: Includes bibliographical references (p. 233-242) and index.; Publication Type: Book, eBook; Physical Description: xx, 254 p. : ill.; Language: English},
author = {Young, Ralph Rowland},
isbn = {9781580536189},
keywords = {Computer software -- Development -- Handbooks,Electronic books,System analysis -- Handbooks,Systems engineering -- Handbooks,etc,man,manuals},
publisher = {Artech House},
series = {Artech House technology management and professional development library},
title = {{The requirements engineering handbook / Ralph R. Young.}},
year = {2004}
}
@article{Guarda2009,
abstract = {Privacy and data protection are pivotal issues in nowadays society. They concern the right to prevent the dissemination of sensitive or confidential information of individuals. Many studies have been proposed on this topic from various perspectives, namely sociological, economic, legal, and technological. We have recognized the legal perspective as being the basis of all other perspectives. Actually, data protection regulations set the legal principles and requirements that must be met by organizations when processing personal data. The objective of this work is to provide a reference base for the development of methodologies tailored to design privacy-aware systems to be compliant with data protection regulations. {\textcopyright} 2008 Elsevier B.V. All rights reserved.},
author = {Guarda, Paolo and Zannone, Nicola},
issn = {09505849},
journal = {Information and Software Technology},
keywords = {Privacy policy,Privacy-Aware Access Control,Privacy-related legal requirements,Requirements Engineering},
month = {feb},
number = {2},
pages = {337--350},
title = {{Towards the development of privacy-aware systems}},
volume = {51},
year = {2009}
}
@inproceedings{Hjerppe2019,
abstract = {The General Data Protection Regulation (GDPR) in the European Union is the most famous recently enacted privacy regulation. Despite of the regulation's legal, political, and technological ramifications, relatively little research has been carried out for better understanding the GDPR's practical implications for requirements engineering and software architectures. Building on a grounded theory approach with close ties to the Finnish software industry, this paper contributes to the sealing of this gap in previous research. Three questions are asked and answered in the context of software development organizations. First, the paper elaborates nine practical constraints under which many small and medium-sized enterprises (SMEs) often operate when implementing solutions that address the new regulatory demands. Second, the paper elicits nine regulatory requirements from the GDPR for software architectures. Third, the paper presents an implementation for a software architecture that complies both with the requirements elicited and the constraints elaborated.},
author = {Hjerppe, Kalle and Ruohonen, Jukka and Lepp{\"{a}}nen, Ville},
booktitle = {Proceedings of the IEEE International Conference on Requirements Engineering},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hjerppe, Ruohonen, Lepp{\"{a}}nen - 2019 - The general data protection regulation Requirements, architectures, and constraints.pdf:pdf},
isbn = {9781728139128},
issn = {23326441},
keywords = {Data protection,GDPR,Law,Privacy,Regulation,Requirements engineering,SMEs,SOA,SOAs,Software architectures,architecture,constraints,requirements},
mendeley-tags = {GDPR,SOAs,architecture,constraints,requirements},
month = {sep},
pages = {265--275},
publisher = {IEEE Computer Society},
title = {{The general data protection regulation: Requirements, architectures, and constraints}},
year = {2019}
}
@misc{Swinhoe2020,
author = {Swinhoe, Dan},
booktitle = {CSO Online},
title = {{The 14 biggest data breaches of the 21st century}},
url = {https://www.csoonline.com/article/2130877/the-biggest-data-breaches-of-the-21st-century.html},
urldate = {2020-03-29},
year = {2020}
}
@misc{PrivacyAffa,
author = {{Privacy Affairs}},
title = {{GDPR Fines List: Find all GDPR fines {\&} detailed statistics}},
url = {https://www.privacyaffairs.com/gdpr-fines/},
year = {2020}
}
@inproceedings{Anthonysamy2017,
abstract = {Software systems are increasingly open, handle large amounts of personal or other sensitive data and are intricately linked with the daily lives of individuals and communities. This poses a range of privacy requirements. Such privacy requirements are typically treated as instances ofrequirements pertaining to compliance, traceability, access control, verification or usability. Though important, such approaches assume that the scope for the privacy requirements can be established a priori and that such scope does not vary drastically once the system is deployed. User data and information, however, exists in an open, hyper-connected and potentially 'unbounded' environment. Furthermore, 'privacy requirements - present'and 'privacy requirements - future' may differ significantly as the privacy implications are often emergent a posteriori. Effective treatment of privacy requirements, therefore, requires techniques and approaches that fit with the inherent openness and fluidity of the environment through which user data and information flows. This paper surveys state of the art and presents some potential directions in the way privacy requirements should be treated. We reflect on the limitations of existing approaches with regards to unbounded privacy requirements and highlight a set of key challenges for requirements engineering research with regards to managing privacy in such unbounded settings.},
author = {Anthonysamy, Pauline and Rashid, Awais and Chitchyan, Ruzanna},
booktitle = {Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering: Software Engineering in Society Track, ICSE-SEIS 2017},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Anthonysamy, Rashid, Chitchyan - 2017 - Privacy requirements Present {\&} future.pdf:pdf},
isbn = {9781538626733},
month = {jun},
pages = {13--22},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Privacy requirements: Present {\&} future}},
year = {2017}
}
@inproceedings{Passonneau2006,
abstract = {Annotation projects dealing with complex semantic or pragmatic phenomena face the dilemma of creating annotation schemes that oversimplify the phenomena, or that capture distinctions conventional reliability metrics cannot measure adequately. The solution to the dilemma is to develop metrics that quantify the decisions that annotators are asked to make. This paper discusses MASI, distance metric for comparing sets, and illustrates its use in quantifying the reliability of a specific dataset. Annotations of Summary Content Units (SCUs) generate models referred to as pyramids which can be used to evaluate unseen human summaries or machine summaries. The paper presents reliability results for five pairs of pyramids created for document sets from the 2003 Document Understanding Conference (DUC). The annotators worked independently of each other. Differences between application of MASI to pyramid annotation and its previous application to co-reference annotation are discussed. In addition, it is argued that a paradigmatic reliability study should relate measures of inter-annotator agreement to independent assessments, such as significance tests of the annotated variables with respect to other phenomena. In effect, what counts as sufficiently reliable intera-annotator agreement depends on the use the annotated data will be put to.},
author = {Passonneau, Rebecca},
booktitle = {Proceedings of the 5th International Conference on Language Resources and Evaluation, LREC 2006},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Passonneau - 2006 - Measuring agreement on set-valued items (MASI) for semantic and pragmatic annotation.pdf:pdf},
pages = {831--836},
title = {{Measuring agreement on set-valued items (MASI) for semantic and pragmatic annotation}},
year = {2006}
}
@misc{Moodle2019,
author = {Moodle},
title = {{Privacy API}},
url = {https://docs.moodle.org/dev/Privacy{\_}API},
urldate = {2020-04-15},
year = {2019}
}
@techreport{Landis1977,
author = {Landis, J Richard and Koch, Gary G},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Landis, Koch - 1977 - The Measurement of Observer Agreement for Categorical Data.pdf:pdf},
number = {1},
pages = {159--174},
title = {{The Measurement of Observer Agreement for Categorical Data}},
volume = {33},
year = {1977}
}
@article{ChunTie2019,
abstract = {Background: Grounded theory is a well-known methodology employed in many research studies. Qualitative and quantitative data generation techniques can be used in a grounded theory study. Grounded theory sets out to discover or construct theory from data, systematically obtained and analysed using comparative analysis. While grounded theory is inherently flexible, it is a complex methodology. Thus, novice researchers strive to understand the discourse and the practical application of grounded theory concepts and processes. Objective: The aim of this article is to provide a contemporary research framework suitable to inform a grounded theory study. Result: This article provides an overview of grounded theory illustrated through a graphic representation of the processes and methods employed in conducting research using this methodology. The framework is presented as a diagrammatic representation of a research design and acts as a visual guide for the novice grounded theory researcher. Discussion: As grounded theory is not a linear process, the framework illustrates the interplay between the essential grounded theory methods and iterative and comparative actions involved. Each of the essential methods and processes that underpin grounded theory are defined in this article. Conclusion: Rather than an engagement in philosophical discussion or a debate of the different genres that can be used in grounded theory, this article illustrates how a framework for a research study design can be used to guide and inform the novice nurse researcher undertaking a study using grounded theory. Research findings and recommendations can contribute to policy or knowledge development, service provision and can reform thinking to initiate change in the substantive area of inquiry. Keywords Framework, grounded theory, grounded theory methods, novice researcher, study design},
author = {{Chun Tie}, Ylona and Birks, Melanie and Francis, Karen},
file = {:C$\backslash$:/Users/ps642/Downloads/Grounded theory research - A design framework for novice researchers.pdf:pdf},
issn = {2050-3121},
journal = {SAGE Open Medicine},
keywords = {10 december 2018,30 july 2018,accepted,date received,framework,grounded theory,grounded theory methods,novice researcher,study design},
pages = {205031211882292},
title = {{Grounded theory research: A design framework for novice researchers}},
volume = {7},
year = {2019}
}
@article{Viera2005,
abstract = {Items such as physical exam findings, radiographic interpretations, or other diagnostic tests often rely on$\backslash$r$\backslash$nsome degree of subjective interpretation by observers. Studies that measure the agreement between two or$\backslash$r$\backslash$nmore observers should include a statistic that takes into account the fact that observers will sometimes$\backslash$r$\backslash$nagree or disagree simply by chance. The kappa statistic (or kappa coefficient) is the most commonly used$\backslash$r$\backslash$nstatistic for this purpose. A kappa of 1 indicates perfect agreement, whereas a kappa of 0 indicates agreement$\backslash$r$\backslash$nequivalent to chance. A limitation of kappa is that it is affected by the prevalence of the finding under$\backslash$r$\backslash$nobservation. Methods to overcome this limitation have been described.$\backslash$r$\backslash$n},
author = {Viera, Anthony J and Garrett, Joanne M},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Viera, Garrett - 2005 - Understanding interobserver agreement the kappa statistic.pdf:pdf},
journal = {Family Medicine},
number = {5},
pages = {360--363},
title = {{Understanding interobserver agreement: the kappa statistic}},
volume = {37},
year = {2005}
}
@inproceedings{Anton2002,
abstract = {Privacy has recently become a prominent issue in the context of electronic commerce websites. Increasingly, Privacy policies posted on such websites are receiving considerable attention from the government and consumers. We have used goal-mining, to extract pre-requirements goals from post-requirements text artifacts, as a technique for analyzing privacy policies. The identified goals are useful for analyzing implicit internal conflicts within privacy policies and conflicts with the corresponding websites and their manner of operation. These goals can be used to reconstruct the implicit requirements met by the privacy policies. This paper interrelates privacy policy and requirements for websites; it introduces a privacy goal taxonomy and reports the analysis of 23 Internet privacy policies for companies in three health care industries: pharmaceutical, health insurance and online drugstores. The evaluated taxonomy provides a valuable framework for requirements engineering practitioners, policy makers and regulatory bodies, and also benefits website users.},
author = {Ant{\'{o}}n, Annie I. and Earp, Julia B. and Reese, Angela},
booktitle = {Proceedings of the IEEE International Conference on Requirements Engineering},
file = {:C$\backslash$:/Users/ps642/Downloads/Analyzing Website Privacy Requirements Using a Privacy Goal Taxonomy.pdf:pdf},
isbn = {0769514650},
issn = {1090705X},
keywords = {Art,Educational institutions,Electronic commerce,Engineering management,Government,Internet,Legislation,Medical services,Privacy,Taxonomy},
title = {{Analyzing Website privacy requirements using a privacy goal taxonomy}},
year = {2002}
}
@techreport{Krippendorff2011,
author = {Krippendorff, Klaus},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Krippendorff - 2011 - Computing Krippendorff's Alpha-Reliability.pdf:pdf},
title = {{Computing Krippendorff's Alpha-Reliability}},
url = {http://repository.upenn.edu/asc{\_}papers/43},
year = {2011}
}
@inproceedings{Bhattacharya2011,
abstract = {Predicting bug-fix time is useful in several areas of software evolution, such as predicting software quality or coordinating development effort during bug triaging. Prior work has proposed bug-fix time prediction models that use various bug report attributes (e.g., number of developers who participated in fixing the bug, bug severity, number of patches, bug-opener's reputation) for estimating the time it will take to fix a newly-reported bug. In this paper we take a step towards constructing more accurate and more general bug-fix time prediction models by showing how existing models fail to validate on large projects widely-used in bug studies. In particular, we used multivariate and univariate regression testing to test the prediction significance of existing models on 512,474 bug reports from five open source projects: Eclipse, Chrome and three products from the Mozilla project (Firefox, Seamonkey and Thunderbird). The results of our regression testing indicate that the predictive power of existing models is between 30{\%} and 49{\%} and that there is a need for more independent variables (attributes) when constructing a prediction model. Additionally, we found that, unlike in prior recent studies on commercial software, in the projects we examined there is no correlation between bug-fix likelihood, bug-opener's reputation and the time it takes to fix a bug. These findings indicate three open research problems: (1) assessing whether prioritizing bugs using bug-opener's reputation is beneficial, (2) identifying attributes which are effective in predicting bug-fix time, and (3) constructing bug-fix time prediction models which can be validated on multiple projects. {\textcopyright} 2011 ACM.},
author = {Bhattacharya, Pamela and Neamtiu, Iulian},
booktitle = {Proceedings - International Conference on Software Engineering},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bhattacharya, Neamtiu - 2011 - Bug-fix time prediction models Can we do better.pdf:pdf},
isbn = {9781450305747},
issn = {02705257},
keywords = {bug report triage,bug-fix time,issue tracking,statistical model},
pages = {207--210},
title = {{Bug-fix time prediction models: Can we do better?}},
year = {2011}
}
@article{Hallgren,
abstract = {Many research designs require the assessment of inter-rater reliability (IRR) to demonstrate consistency among observational ratings provided by multiple coders. However, many studies use incorrect statistical procedures, fail to fully report the information necessary to interpret their results, or do not address how IRR affects the power of their subsequent analyses for hypothesis testing. This paper provides an overview of methodological issues related to the assessment of IRR with a focus on study design, selection of appropriate statistics, and the computation, interpretation, and reporting of some commonly-used IRR statistics. Computational examples include SPSS and R syntax for computing Cohen's kappa and intra-class correlations to assess IRR.},
author = {Hallgren, Kevin A.},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hallgren - 2012 - Computing inter-rater reliability for observational data An overview and tutorial.pdf:pdf},
journal = {Tutorials in Quantitative Methods for Psychology},
keywords = {behavioral observation,coding,inter-rater agreement,intra-class correlation,kappa,reliability,tutorial},
number = {1},
pages = {23--34},
title = {{Computing inter-rater reliability for observational data: An overview and tutorial.}},
volume = {8},
year = {2012}
}
@inproceedings{Perera2016,
abstract = {The Internet of Things (IoT) systems are designed and developed either as standalone applications from the ground-up or with the help of IoT middleware platforms. They are designed to support different kinds of scenarios, such as smart homes and smart cities. Thus far, privacy concerns have not been explicitly considered by IoT applications and middleware platforms. This is partly due to the lack of systematic methods for designing privacy that can guide the software development process in IoT. In this paper, we propose a set of guidelines, a privacyby-design framework, that can be used to assess privacy capabilities and gaps of existing IoT applications as well as middleware platforms. We have evaluated two open source IoT middleware platforms, namely OpenIoT and Eclipse SmartHome, to demonstrate how our framework can be used in this way.},
author = {Perera, Charith and McCormick, Ciaran and Bandara, Arosha K. and Price, Blaine A. and Nuseibeh, Bashar},
booktitle = {ACM International Conference Proceeding Series},
isbn = {9781450348140},
keywords = {Internet of Things,Privacy,Software Engineering},
pages = {83--92},
title = {{Privacy-by-design framework for assessing internet of things applications and platforms}},
year = {2016}
}
@inproceedings{Ravenscroft2016,
abstract = {With the constant growth of the scientific literature, automated processes to enable access to its contents are increasingly in demand. Several functional discourse annotation schemes have been proposed to facilitate information extraction and summarisation from scientific articles, the most well known being argumentative zoning. Core Scientific concepts (CoreSC) is a three layered fine-grained annotation scheme providing content-based annotations at the sentence level and has been used to index, extract and summarise scientific publications in the biomedical literature. A previously developed CoreSC corpus on which existing automated tools have been trained contains a single annotation for each sentence. However, it is the case that more than one CoreSC concept can appear in the same sentence. Here, we present the Multi-CoreSC CRA corpus, a text corpus specific to the domain of cancer risk assessment (CRA), consisting of 50 full text papers, each of which contains sentences annotated with one or more CoreSCs. The full text papers have been annotated by three biology experts. We present several inter-annotator agreement measures appropriate for multi-label annotation assessment. Employing several inter-annotator agreement measures, we were able to identify the most reliable annotator and we built a harmonised consensus (gold standard) from the three different annotators, while also taking concept priority (as specified in the guidelines) into account. We also show that the new Multi-CoreSC CRA corpus allows us to improve performance in the recognition of CoreSCs. The updated guidelines, the multi-label CoreSC CRA corpus and other relevant, related materials are available at the time of publication at http://www.sapientaproject.com/.},
author = {Ravenscroft, James and Oellrich, Anika and Saha, Shyamasree and Liakata, Maria},
booktitle = {Proceedings of the 10th International Conference on Language Resources and Evaluation, LREC 2016},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ravenscroft et al. - 2016 - Multi-label annotation in scientific articles - The multi-label cancer risk assessment corpus.pdf:pdf},
isbn = {9782951740891},
keywords = {Cancer risk assessment,Core Scientific concepts,Functional discourse,Multi-label annotations,Scientific discourse},
pages = {4115--4123},
title = {{Multi-label annotation in scientific articles - The multi-label cancer risk assessment corpus}},
year = {2016}
}
@techreport{OfficeJournaloftheEuropeanUnion;2016,
author = {{Office Journal of the European Union}},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Office Journal of the European Union - 2016 - Regulation (EU) 2016679 of the European Parliament and of the Council of 27 April 2016 on.pdf:pdf},
keywords = {GDPR},
mendeley-tags = {GDPR},
pages = {1--88},
title = {{General Data Protection Regulation (GDPR)}},
url = {https://eur-lex.europa.eu/legal-content/EN/TXT/PDF/?uri=CELEX:32016R0679},
year = {2016}
}
@techreport{EuropeanCommission2019,
author = {{European Commission}},
file = {:C$\backslash$:/Users/ps642/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/European Commission - 2019 - GDPR IN NUMBERS 2019 {\#}HAPPYBIRTHDAYGDPR.pdf:pdf},
title = {{GDPR IN NUMBERS 2019 {\#}HAPPYBIRTHDAYGDPR}},
year = {2019}
}
@article{Fleiss1971,
abstract = {Introduced the statistic kappa to measure nominal scale agreement between a fixed pair of raters. Kappa was generalized to the case where each of a sample of 30 patients was rated on a nominal scale by the same number of psychiatrist raters (n = 6), but where the raters rating 1 s were not necessarily the same as those rating another. Large sample standard errors were derived. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
annote = {Accession Number: 1972-05083-001. Partial author list: First Author {\&} Affiliation: Fleiss, Joseph L.; New York State Dept. of Mental Hygiene, Biometrics Research, New York. Other Publishers: Psychological Review Company; The Macmillan Company; The Review Publishing Company. Release Date: 20060329. Publication Type: Journal (0100), Peer Reviewed Journal (0110). Format Covered: Print. Document Type: Journal Article. Language: English. Major Descriptor: Measurement; Psychiatric Patients; Psychodiagnosis; Statistical Analysis. Classification: Health {\&} Mental Health Treatment {\&} Prevention (3300). Population: Human (10). References Available: Y. Page Count: 5. Issue Publication Date: Nov, 1971. Copyright Statement: American Psychological Association. 1971.},
author = {Fleiss, Joseph L},
issn = {0033-2909},
journal = {Psychological Bulletin},
keywords = {Measurement,Psychiatric Patients,Psychodiagnosis,Statistical Analysis,nominal scale agreement measurement among many rat,rating of psychiatric patients,statistic kappa},
month = {nov},
number = {5},
pages = {378--382},
publisher = {American Psychological Association},
title = {{Measuring nominal scale agreement among many raters}},
volume = {76},
year = {1971}
}
@misc{Projects,
author = {{The Chromium Projects}},
title = {{The Chromium Projects}},
url = {https://www.chromium.org/chromium-projects},
urldate = {2020-04-07},
year = {2020}
}
